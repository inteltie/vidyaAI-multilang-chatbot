# VidyaAI-AGENT: Quick Reference Guide

A one-page guide for new maintainers to quickly understand the system.

---

## ğŸ¯ What Does This System Do?

An educational chatbot that answers student and teacher questions about curriculum by:
1. Analyzing the question (what language? what type of question?)
2. Retrieving relevant educational documents
3. Generating a tailored response
4. Validating the response isn't hallucinated
5. Translating back to user's language
6. Storing conversation for context

---

## ğŸ—ï¸ High-Level Flow

```
User Asks Question
    â†“
Load Previous Chat History (Redis + MongoDB)
    â†“
Analyze Query (Language â†’ English, Classify Type, Extract Context)
    â†“
Route to Agent (Conversational OR Educational)
    â†“
Retrieve Documents from Pinecone (Dense + Sparse Hybrid Search)
    â†“
Agent Generates Response (with Tools: Retrieval + Web Search)
    â†“
Validate Response (Against Documents, Check for Hallucinations)
    â†“
Translate Back to User's Language
    â†“
Save to Chat History (Redis + MongoDB)
    â†“
Return Response to User
```

---

## ğŸ”§ Key Configuration (What You Can Adjust)

Located in `.env` file:

```env
# Response Length Limits
MAX_TOKENS_BRIEF=800              # Short answers
MAX_TOKENS_DEFAULT=1500           # Standard answers
MAX_TOKENS_DETAILED=3000          # Deep explanations

# Memory Settings
MEMORY_BUFFER_SIZE=20             # How many message turns to remember
MEMORY_TOKEN_LIMIT=2000           # Max tokens in memory

# Search Settings
RETRIEVER_TOP_K=5                 # How many documents to retrieve
RETRIEVER_SCORE_THRESHOLD=0.45    # Min match quality for retrieval (0-1)
CITATION_SCORE_THRESHOLD=0.6      # Min score for final citations

# Agent Settings
MAX_ITERATIONS=5                  # Max tool use loops
WEB_SEARCH_ENABLED=true          # Allow web search fallback

# LLM Settings
MODEL_NAME=gpt-4o-mini            # Which GPT model to use
LLM_TEMPERATURE=0.0               # 0 = deterministic, 1 = creative
```

---

## ğŸ“Š Request Processing (What Happens When)

### 1ï¸âƒ£ LoadMemoryNode
- **When**: First step, always
- **What**: Loads conversation history
- **From**: Redis (fast) or MongoDB (persistent)
- **Outputs**: Session object, message buffer, conversation summary

### 2ï¸âƒ£ AnalyzeQueryNode â­ (Merged Step - Does Multiple Things)
- **When**: Right after loading memory
- **What**: 
  - Detects user's language (English? Spanish? Hindi?)
  - Translates to English if needed
  - Classifies question type (chat vs curriculum)
  - Extracts metadata (class level, subject, chapter, lecture)
  - **Proactively fetches documents** (optimization)
- **Outputs**: `query_type`, `translated_query`, `documents`, `session_metadata`

### 3ï¸âƒ£ Routing Decision
- **If** query_type = "conversational" (hi, thanks, hello) â†’ **ConversationalAgent**
- **If** query_type = "curriculum_specific" (any education question):
  - **If** user_type = "teacher" â†’ **TeacherAgent**
  - **If** agent_mode = "interactive" â†’ **InteractiveStudentAgent**
  - **Otherwise** â†’ **StudentAgent**

### 4ï¸âƒ£ Agent Nodes (Student/Teacher/Conversational)
- **What**: Generate the answer
- **Tools Available**:
  - RetrievalTool: Search curriculum documents
  - WebSearchTool: Search internet (if docs insufficient)
- **Max Iterations**: 5 (prevents infinite loops)
- **Output**: `response` text

### 5ï¸âƒ£ GroundednessCheckNode (Validation) ğŸ›¡ï¸
- **When**: After educational agents only
- **What**: Checks if response is:
  - Supported by retrieved documents? (groundedness)
  - Answering the right question? (intent alignment)
  - Ambiguous? (needs user clarification?)
- **Outcomes**:
  - âœ… `is_valid=True` â†’ Continue
  - âŒ `is_valid=False` â†’ Retry agent (1x only)
  - â“ `needs_clarification=True` â†’ Ask user which interpretation

### 6ï¸âƒ£ TranslateResponseNode
- **When**: Before returning to user
- **What**: Translates response back to user's original language
- **If**: User asked in Spanish, response is in Spanish (even if generated in English)

### 7ï¸âƒ£ SaveMemoryNode
- **When**: At the very end
- **What**: Saves message to both storages
  - Redis: Immediate (for next request)
  - MongoDB: Background async task
- **Also**: Updates summary every 20 messages

---

## ğŸ’¾ How Caching & Memory Works

### Three-Layer Storage

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. REDIS (Hot Cache - 1 hour TTL)                   â”‚
â”‚    - Current conversation buffer (last 30 messages) â”‚
â”‚    - Web search results (24 hour TTL)               â”‚
â”‚    - API response cache                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2. MONGODB (Cold Storage - Permanent)               â”‚
â”‚    - Full message history                           â”‚
â”‚    - Session summaries (updated every 20 messages)  â”‚
â”‚    - Metadata and analytics                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3. PINECONE (Vector DB - Permanent)                 â”‚
â”‚    - Educational documents with embeddings          â”‚
â”‚    - Searchable by: subject, chapter, class, etc.   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Token Budget Management

The system **never exceeds token limits** through trimming:

```
Trimming Strategy:
1. Include summary (context w/o tokens)
2. Add trimmed message history (up to 2000 tokens)
3. Add system prompt
4. Add current query
5. Total must fit in model's context window

If too many tokens: Drop oldest messages first
                    Keep most recent conversation
```

### Summaries (Generated Every 20 Messages)

```
OLD Summary: "User asked about photosynthesis and chlorophyll"
Last 20 Messages: [user: glucose?, assistant: glucose is..., etc.]
New Summary: "User learned photosynthesis, chlorophyll, glucose synthesis"
Stored in: MongoDB ChatSession document
Used in: LLM system prompt (doesn't count tokens)
```

---

## ğŸ” How Retrieval & Search Works

### Retrieval Tool (RAG)

**Used For**: Educational questions about curriculum

**How It Works**:
```
1. Embed query using OpenAI embeddings (dense vector)
2. Create keyword index using BM25 (sparse vector)
3. Hybrid search: 80% dense + 20% sparse (alpha=0.8)
4. Filter by: class_level, subject, chapter, lecture_id (STRICT: only from request body)
5. Return top 5 documents (if score > 0.45)
6. Citations filtered at score > 0.6 for final display
```

**Documents Look Like**:
```json
{
  "id": "doc_12345",
  "score": 0.87,
  "text": "Photosynthesis is the process...",
  "metadata": {
    "lecture_id": 42,
    "subject": "Biology",
    "chapter": "Plant Processes",
    "class_level": "Class 10",
    "teacher_name": "Dr. Smith"
  }
}
```

### Web Search Tool

**Used For**: When RAG doesn't have enough info OR for current events

**How It Works**:
```
1. Check Redis cache first (24-hour TTL)
2. If not cached: Call OpenAI native web search
3. Get concise summary of web results
4. Cache result for 24 hours
```

**IMPORTANT**: Web search results are for **internal context only**. They are NEVER cited or mentioned to students. Only curriculum materials (Lecture IDs) are cited.

### When Each Is Used

| Situation | Tool | Reason |
|-----------|------|--------|
| Student asks about photosynthesis | Retrieval | Curriculum content |
| Student asks about 2024 election | Web Search | Not in curriculum |
| Teacher asks about pedagogy | Web Search | Latest methods |
| No retrieval results found | Web Search | Fallback |
| Conversational (hi, thanks) | Neither | Direct LLM response |

---

## ğŸ¤– Four Types of Agents

### 1. ConversationalAgent
- **For**: Greetings, small talk, thanks
- **Tools**: None (no retrieval)
- **Max Tokens**: 800
- **Behavior**: Friendly, quick responses
- **Examples**: "Hi!", "How are you?", "Thanks for the help!"

### 2. StudentAgent (Standard) - With Grade Personas
- **For**: Student with curriculum questions
- **Tools**: Retrieval + Web Search (optional)
- **Max Tokens**: 1500
- **Behavior**: Adapts to student grade level (A/B/C/D)
- **Grade Personas**:
  - **Grade A**: "The Analytic Architect" - Technical depth, uses term "Kinetic Impedance", ends with "What if..." questions
  - **Grade B**: "The Structured Scholar" (Default) - Clear definitions, standard academic structure
  - **Grade C**: "The Helpful Neighbor" - Analogies like "sandpaper", real-world examples, encouraging
  - **Grade D**: "The Foundational Coach" - Simple stories, no jargon, "You've got this!" framing

### 3. InteractiveStudentAgent (Socratic)
- **For**: Student who wants to learn through questioning
- **Tools**: Retrieval + Web Search (optional)
- **Max Tokens**: 1500
- **Behavior**: Asks guiding questions instead of answers, also uses grade personas
- **Style**: "What do you already know about this? â†’ Let's think about X â†’ What does that tell you?"

### 4. TeacherAgent
- **For**: Teachers requesting pedagogical guidance
- **Tools**: Retrieval + Web Search (optional)
- **Max Tokens**: 3000
- **Behavior**: Scholarly, analytical, content review
- **Style**: "Coverage Analysis: You covered X in session Y. Topics: 1. A, 2. B, 3. C [Citations: session_10, session_12]"

---

## ğŸš¨ Query Type Classification

### How It Works

1. **Check Heuristics** (fast, no LLM):
   - "hi", "hello", "thanks" â†’ conversational

2. **LLM Classification** (if not obvious):
   - Analyzes: current query + last 4 messages
   - Decides: conversational OR curriculum_specific
   - Also extracts: class_level, subject, chapter, lecture_id

### Classification Result

```python
{
  "query_type": "curriculum_specific",           # or "conversational"
  "translated_query": "Explain photosynthesis",  # in English
  "confidence": 0.98,
  "subjects": ["Biology", "Science"],
  "class_level": "Class 10",
  "chapter": "Plant Processes",
  "lecture_id": "42"
}
```

---

## ğŸ“ˆ Performance Metrics to Track

### Key Numbers in `config.py`

| Metric | Default | Impact |
|--------|---------|--------|
| `retriever_top_k` | 5 | More = slower but more info |
| `retriever_score_threshold` | 0.45 | Higher = fewer but better docs |
| `citation_score_threshold` | 0.6 | Only high-quality citations shown |
| `max_iterations` | 5 | Max tool use loops |
| `memory_token_limit` | 2000 | More = better context, slower |
| `memory_buffer_size` | 20 | More = better context, slower |
| `web_search_enabled` | true | Enable/disable web fallback |

### Response Time Factors

1. **Embedding** (~500ms): Convert query to vector
2. **Retrieval** (~1s): Search Pinecone
3. **LLM Call** (~1-3s): Generate response
4. **Validation** (~1s): Check groundedness
5. **Translation** (~500ms): If needed

**Total**: ~3-6 seconds typical

---

## ğŸ› Debugging Checklist

When something goes wrong:

```
â–¡ Check .env variables are set correctly
â–¡ Check Redis is running: redis-cli ping
â–¡ Check MongoDB is running: mongo --eval "db.adminCommand('ping')"
â–¡ Check OpenAI API key is valid
â–¡ Check Pinecone index name and API key
â–¡ Look at logs: docker-compose logs -f api
â–¡ Check Redis cache: redis-cli KEYS "chat:*"
â–¡ Check MongoDB docs: db.chatsessions.find({})
â–¡ Verify document retrieval: Test retriever.py directly
```

---

## ğŸ“š File Structure Cheat Sheet

```
main.py                      â† FastAPI app entry point
config.py                    â† Configuration & environment
graph.py                     â† LangGraph workflow (node connections)
state.py                     â† Data structures (AgentState, etc.)

services/
  â”œâ”€ query_classifier.py     â† Classify query type
  â”œâ”€ chat_memory.py          â† Redis + MongoDB memory management
  â”œâ”€ retriever.py            â† Pinecone hybrid search
  â”œâ”€ response_validator.py   â† Groundedness checking
  â”œâ”€ translator.py           â† Language translation
  â””â”€ citation_service.py     â† Extract citations from documents

agents/
  â”œâ”€ student_agent.py        â† Standard student responses
  â”œâ”€ interactive_student_agent.py  â† Socratic questions
  â”œâ”€ teacher_agent.py        â† Teacher guidance
  â”œâ”€ conversational_agent.py  â† Chat responses
  â””â”€ react_agent.py          â† ReAct loop (tool use)

nodes/
  â”œâ”€ load_memory.py          â† Load chat history
  â”œâ”€ analyze_query.py        â† Translate + classify + extract
  â”œâ”€ groundedness_check.py    â† Validate response
  â”œâ”€ translate_response.py    â† Translate to user language
  â””â”€ save_memory.py          â† Save to Redis + MongoDB

tools/
  â”œâ”€ retrieval_tool.py       â† Search curriculum documents
  â””â”€ web_search_tool.py      â† Search internet

models/
  â”œâ”€ chat.py                 â† ChatRequest, ChatResponse
  â””â”€ domain.py               â† QueryIntent, ChatSession
```

---

## ğŸ”— Dependencies You Should Know

| Package | Role | Why |
|---------|------|-----|
| `langgraph` | Workflow orchestration | Manage node flow |
| `langchain` | LLM abstractions | Simplify OpenAI calls |
| `fastapi` | Web framework | HTTP API |
| `redis` | Caching | Fast memory |
| `motor` + `beanie` | MongoDB async | Persistent storage |
| `pinecone` | Vector search | Document retrieval |
| `openai` | LLM API | Generate responses |

---

## ğŸ’¡ Key Insights for Maintenance

1. **Everything is async** - Never use `.get()` without `await`
2. **Tokens are expensive** - Always trim and summarize
3. **Cache aggressively** - Web results, embeddings, classifications
4. **Validate always** - Groundedness check prevents hallucinations
5. **Handle errors gracefully** - Fallback to web search if retrieval fails
6. **Monitor memory** - Watch Redis/MongoDB growth
7. **Temperature is 0** - Responses are deterministic (reproducible)
8. **Filters are strict** - User's class/subject filters are enforced

---

## ğŸš€ Common Tasks

### Add a New Agent Type
1. Create `agents/my_agent.py` (implement `Agent` protocol)
2. Create node in `nodes/my_agent_node.py`
3. Register in `graph.py` (add_node + add_edge)
4. Add routing logic in `_route_to_agent()` or `_route_educational_user()`

### Change Token Limits
1. Edit `.env`:
   ```
   MAX_TOKENS_DEFAULT=2000
   ```
2. Restart API

### Improve Retrieval Quality
1. Adjust in `.env`:
   ```
   RETRIEVER_TOP_K=10           # Get more docs
   RETRIEVER_SCORE_THRESHOLD=0.6  # Stricter matching
   ```
2. Test with sample queries

### Debug Memory Issues
1. Check Redis:
   ```bash
   redis-cli LRANGE chat:{session_id}:buffer 0 -1
   ```
2. Check MongoDB:
   ```bash
   db.chatsessions.findOne({session_id: "{session_id}"})
   ```

---

## ğŸ“ Learning Path for New Maintainers

1. **Day 1**: Read this guide + PROJECT_OVERVIEW.md
2. **Day 2**: Run locally, trace through a sample request
3. **Day 3**: Understand config.py + state.py
4. **Day 4**: Trace graph.py (node connections)
5. **Day 5**: Study memory management (chat_memory.py)
6. **Week 2**: Study agents and tools
7. **Week 3**: Study validation and error handling

---

**Last Updated**: January 2026
**Maintained By**: Your Team
**Questions?** Check inline code comments and PROJECT_OVERVIEW.md
